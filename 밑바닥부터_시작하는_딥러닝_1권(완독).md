*Chapter2 <퍼셉트론>*

- 퍼셉트론을 쌓으면 비선형 표현이 가능하다. -> 신경망

*Chapter3 <신경망>*

**Activation function**

- Sigmoid function
h(x) = 1/(1 + exp(-x))

- Step function
h(x) = if x > 0: 1 else 0

- 위의 둘 모두 비선형 함수임. 선형 함수를 사용하면 층을 깊게 쌓는 의미가 없어짐.

- Relu(Rectified Linear Unit) function <- 자주 쓰임.
h(x) = if x > 0: x else 0

- Softmax function(분모 출력 총합1, 함수의 출력은 확률로 해석)
$\text{softmax}(z_i) = \frac{e^{z_i}}{\sum_{j=1}^N e^{z_j}}$ -> 지수 함수 때문에 overflow 문제 생김 -> $\text{softmax}(z_i) = \frac{e^{z_i - C}}{\sum_{j=1}^N e^{z_j - C}}, \quad \text{where } C = \max(z)$

**출력층의 활성화 함수**
- 회귀에는 항등 함수(입력값 그대로 출력).
- 2클래스 분류에는 시그모이도 함수.
- 다중 클래스 분류에는 소프트맥스 함수.

- 학습을 끝낸 실제 분류 시에는 출력층의 activation function 생략하는 경우도 있음. 어차피 최댓값의 순서는 달라지지 않기 때문.
- 분류 시 출력층의 뉴런 수는 분류할 레이블 개수와 같다.
- 출력 과정은 신경망의 순전파(forward propagation)라고 함.

- 입력 데이터를 묶은 것을 배치라 하며 추론 처리를 이 배치 단위로 진행하면 결과를 더 빠르게 얻을 수 있다.. 

*Chapter4 <신경망 학습>*

**오차제곱합 SSE(Sum of squares for error)**
- ![image](https://github.com/user-attachments/assets/5531db7b-dde6-4e94-9386-e62b26483fab)

**교차 엔트로피 오차 CEE(Cross entropy error)**
- ![image](https://github.com/user-attachments/assets/ab1e7054-e13e-429f-9f50-02c479be01f0)
- y는 정답 레이블, y_hat은 확률값
- 이 수식의 전제는 레이블이 원-핫 인코딩이 된 것이므로 정답일때는 y가 1, 오답일때는 y가 0임
- ![image](https://github.com/user-attachments/assets/c27967bc-2c6e-46a0-b5df-5d0f26946bae)
- 이 수식은 위의 수식에서 N개의 데이터의 k번째 값을 의미함.

- 신경망을 학습할 때 정확도를 지표로 삼아서는 안 됨. 정확도를 지표로 하면 매개변수의 미분값이 대부분의 장소에서 0이 되기 때문. (Step function을 안 쓰는 것도 같은 맥락임.)

**수치 미분(numerical differentiation, <-> 해석적(analytic) 미분): 아주 작은 차분으로 미분(사실상 단순 나눗셈해 근사)하는 것.**
- 실제 미분 수식을 이용하면 반올림 오차(rounding error) 발생함.
- 해결책1: 보통 미분의 분모 h의 값은 10^-4를 이용하면 좋은 결과를 얻는다 알려짐.
- 해결책2: 중앙 차분 이용.

- 함수가 기울기가 0에 가깝게 되는 지점은 보통 극값과 안장점(Saddle point), 고원(Plateau)임.
- 안장점은 말 안장과 같은 모양이고 고원은 평평한 지점임.
- 학습률은 lr, learning rate라 부름.

*Chapter5 <오차역전파법>*

- 자세한 수식 설명은 나중에..

**Affine 계층**
- Y = XW + B 형태로 행렬곱에 덧셈이 첨가된 형태. 이를 affine 변환(transformation)이라고도 함.

*Chapter6 <학습 관련 기술들>*

**AdaGrad**
- 학습률 감소(learning rate decay)를 이용해 처음에는 크게 학습하다가 조금씩 작게 학습하는 기법을 이용함.
- 또한 매개변수의 원소마다 개별적으로 갱신 정도를 조정함. -> 좀 더 효율적 조정 가능.
- ![image](https://github.com/user-attachments/assets/20247bda-e31e-4b6f-b1fb-b274f5bb6ab0)
- AdaGrad는 과거의 기울기를 제곱해 계속 더하는데, 학습이 길어지면 갱신량이 0에 점점 가까워져 갱신이 안 됨. -> 이를 개선한 기법이 RMSProp(과거의 기울기를 점점 잊어가며 새로운 정보 반영, 이를 EMA: Exponential Moving Average를 이용한 방식이라 함.)

**은닉층의 활성화값 분포**
- 활성화값들이 0 또는 1에 치우쳐 분포되어있으면 기울기 소실 문제 발생(시그모이드 함수가 활성화 함수일 때).
- 0.5 부근에 집중되어도 표현력이 제한됨(여러 뉴런을 쓰는 이유가 없어짐).
- 이를 방지하고 은닉층의 활성화값들을 다양하게 하려면 가중치 초깃값을 Xavier 초깃값을 이용해야함(활성화 함수가 선형에 가까운 sigmoid와 tanh에 알맞음.).
- ReLU에 특화된 초깃값은 He 초깃값임.

**배치 정규화(Batch Normalization)**
- 각 층의 활성화값 분포를 퍼뜨리도록 강제함.

장점
- 학습 속도 개선
- 초긱값에 크게 의존하지 않는다
- 오버피팅 감소

**오버피팅**
- 주로 1. 매개변수가 많고 표현력이 높은 모델 또는 2. 훈련 데이터가 적은 경우에 발생.

가중치 감소(weight decay)
- 오버피팅 억제를 위해 사용.
- L1, L2 Regularization을 이용해 적용함.

드롭아웃(Dropout)

**데이터 분류**
- 훈련 데이터: 매개변수 학습
- 검증 데이터: 하이퍼파라미터 성능 평가
- 시험 데이터: 신경망의 범용 성능 평가

하이퍼파라미터 최적화
- 일반적으로 최적 값이 존재하는 범위를 조금씩 줄여가며 함.
- 그리드 서치(Grid Search)보다는 무작위 샘플링 탐색이 좋은 결과를 낸다고 알려져 있음.
- 일반적으로 0.001에서 1,000 사이 10의 거듭제곱 단위로 범위 지정(로그 스케일 지정).

- 정리하면 하이퍼파라미터 값의 범위 설정 -> 설정된 범위에서 값 무작위 추출 -> 해당 값으로 학습 후 검증 데이터로 정확도 평가(에폭은 작게) -> 1, 2단계의 반복 후 범위를 좁혀 다시 반복 후 결정
- 수학적으로 엄밀하고 효율적으로 최적화 수행하려면 베이즈 정리를 이용한 베이즈 최적화(Bayesian optimization)를 이용함.

*Chapter7 <합성곱 신경망(CNN)>*

- 특징 맵(Feature Map): 합성곱 계층의 입출력 데이터.
- 합성곱 계층의 입력 데이터는 입력 특징 맵, 출력 데이터는 출력 특징 맵이라 부름.

**합성 곱 연산(이미지 처리의 필터 연산)**
- 필터를 커널이라고도 함.
- 필터의 원도우(window)를 일정 간격으로 이동해가며 입력 데이터에 적용함.

- 패딩: 출력 크기 조정과 모서리 값이 무시되는 문제 해결.

- 3차원 데이터의 배치 처리를 위해서는 (데이터 수, 채널 수, 높이, 너비) 순으로 4차원 데이터로 바꾸어 처리함.

LeNet
- 손글씨 숫자를 인식하는 네트워크로, 1998년 제안됨.
- 첫 번째 CNN.
- 합성곱 계층과 원시 풀링 계층(서브샘플링으로 원소를 줄이기만 함)을 반복하다가 FC layer를 거치고 결과 출력.
- 활성화 함수로 sigmoid만 사용.

AlexNet
- 위와 비슷하나 활성화 함수로 ReLU 사용, LRN(Local Response Normalization)이라는 국소적 정규화 계층 존재, 드롭아웃 사용.

*Chapter8 <딥러닝>*

- 데이터 확장(Data augmentation): 이미지 회전, 이동 등으로 변형 또는 이미지 일부를 잘라내거나(Crop) 좌우를 뒤집는(Flip) 기법도 있음.
- 층을 깊게 하는 이유 중 하나는 신경망의 매개변수가 상대적으로 적게 해서 같은 수준의 표현력을 달성할 수 있기 때문임. 또한 학습해야 할 문제를 계층적으로 분해할 수 있다는 장점도 있음. (풀어야 할 문제의 분해)

**딥러닝의 초기 역사**
- 이미지넷(ImageNet): 100만 장 이상의 이미지 데이터셋
- ILSVRC: 이미지넷을 이용한 이미지 분류 대회(1,000개 클래스)

VGG
- 합성곱 계층과 풀링 계층으로 구성된 기본적 CNN.
- 16층이면 VGG16, 19층이면 VGG19.

GoogLeNet
- 자세한 것은 원논문 참조.

ResNet(Residual Network)
- 마이크로스프트 팀 개발.
- 스킵 연결(skip connection)을 이용해 층이 깊어도 효율적 학습 가능하게 함.
- VGG 신경망 기반으로 스킵 연결을 도입함. 합성곱 계층을 2개 층마다 건너뛰며 층을 깊게 해 150층 이상으로 높은 정확도 달성.

전이 학습(Transfer learning)
- 학습된 가중치를 다른 신경망에 복사한 후 재학습(Fine tuning).
- 보유한 데이터셋이 적을때 특히 유용.

**딥러닝 고속화**
- 합성곱 계층에서의 연산 시간이 긺 -> GPU를 이용해 해결.
- CUDA, cuDNN등을 이용해 구현.

**분산 학습**
- 딥러닝 연산을 GPU로 가속해도 시간이 오래 걸림 -> 딥러닝 학습을 수평 확장하려는 아이디어 등장.
- 프레임워크가 어느 정도 해줌.
- 좀 예전 책이라 내용이 좀 구식인듯..

**연산 정밀도와 비트 줄이기**
- 실제 딥러닝 학습시 16비트 반정밀도(Half-precision)을 이용해도 큰 문제가 없음.
- 넘파이도 16비트 반정밀도 지원.
- 가중치와 중간 데이터를 1비트로 표현하는 방법도 등장함.

**딥러닝의 활용(컴퓨터 비전 예시)**

R-CNN(Regions With Convolution Neural Network)
- CNN을 사용한 사물 검출 기법.
- 입력 이미지 -> 후보 영역 추출 -> CNN 특징 계산 -> 영역 분류 의 단계로 검출.
- Selective Search 기법, Faster R-CNN 기법 등 존재.

분할(Segmentation)
- 이미지를 픽셀 수준에서 분류하는 것.
- 객체마다 채색된 지도(Supervised) 데이터를 이용해 학습.
- FCN(Fully Convolution Network) 기법: 단 한 번의 forward 처리로 모든 픽셀의 클래스 분류해줌.
- 자세한 내용은 논문 참고.

사진 캡션 생성
- 컴퓨터 비전과 자연어를 융합한 기법으로, 사진을 주면 해당 사진을 설명하는 글을 자동으로 생성.
- NIC(Neural Image Caption) 모델이 대표적. (CNN, RNN으로 구성.)

- 멀티모달 처리(Multimodal Processing): 여러 종류의 정보를 조합하고 처리하는 분야.

GAN 
- 이미지 생성 모델로 생성자(Generator)와 식별자(Discriminator)로 불리는 2개의 신경망을 이용.
- 생성자는 진짜와 똑같은 이미지 생성, 식별자는 그것이 진짜 이미지인지 판정.
- 둘을 겨루도록 학습시켜 생성자는 더 정교한 가짜 이미지를 생성하고 식별자는 더 정확하게 간파할 수 있게 함 -> 생성자가 만든 최종 결과물은 매우 현실적이게 됨.

자율 주행
- SetNet: CNN 기반 신경망으로 주변 환경을 정확하게 인식.

강화학습(Reinforcement Learning)
- 에이전트가 환경에 맞게 행동을 선택하고 그 행동에 의해서 환경이 변함.
- 환경이 변화하면 에이전트는 보상을 얻음.
- 에이전트는 더 나은 보상을 받는 쪽으로 행동 지침이 수정됨.
- DQN(Deep Q-Network): Q학습이라는 강화학습 알고리즘을 기초로 한 강화학습.
- 알파고도 딥러닝과 강화학습이 이용됨.
