*Chapter1*

AI -> ML -> DL 순으로 영역 좁아짐. ML의 핵심은 데이터 기반으로 학습한다는 점임. (<-> 규칙 기반)

**AI 번역**

- 번역 문제의 하나의 데이터는 원문과 그에 대응하는 번역문으로 구성된 쌍.
- 학습에 사용되지 않은 새로운 문장을 입력해 번역된 문장의 정확성을 확인해 모델 성능 평가함(Perplexity: 예측 능력 수치화, BLEU Score: 번역 품질 수치화).
- 토크나이징: 텍스트가 숫자가 아니기 때문에 처리하는 전처리 과정. 텍스트를 적절한 단위로 나누는 작업을 의미함.
ex) 나는 학생입니다 -> 나는/학생/입니다 의 세 토큰으로 나눔.
- 정리하면 자연어 처리의 번역 작업은 '텍스트 -> 숫자 시퀀스 변환 후 입력 -> 숫자 시퀀스 출력 -> 텍스트로 변환'임.

**지도 학습(Supervised Learning)**

- 머신러닝의 학습 방식은 지도 학습, 비지도 학습, 자기 지도 학습, 강화 학습으로 나눌 수 있음.

지도 학습이란 정답을 알고 있는 상태에서 학습하는 방식.
- 각 입력 데이터에 대한 정답을 부여하는 데이터 라벨링이 필수적
- 회귀(Regression, 연속적 레이블)와 분류(Classification, 이산적 레이블)로 나뉘어짐, 기계 번역은 토큰 분류라는 관점에서 분류이다.

컴퓨터 비전 분야 예시
- 분류(Classification): 이미지가 무엇을 나타내는지 하나의 클래스로 나타내는 것. 세 개 이상의 클래스를 포함하는 다중 분류도 있음.
- 위치 추정(Localization): 분류와 함께 수행되며 이미지 내 객체의 클래스를 판단하고 동시에 위치를 출력하는 것(박스의 중심 좌표, 높이, 너비를 나타냄). 박스 정보 예측은 회귀임.
- 객체 탐지(Object Detection): 한 이미지 내 여러 객체의 분류 및 위치 추정을 동시 수행.
ex) YOLO는 이미지를 그리드로 나누어 각 그리드 셀에서 분류 및 각각의 바운딩 박스에 대한 신뢰도(그리드 셀 내 객체의 중심이 존재할 가능성과 예측된 박스가 실제 객체와 겹치는 정도를 곱한 값)와 박스 정보(중심 좌표, 높이, 너비)를 예측함.
- 분할(Segmentation): 이미지의 모든 픽셀을 대상으로 각 픽셀이 어떤 클래스에 해당하는지 판단(이제 네모가 아닌 객체의 모양으로 출력 가능)
- 인스턴스 분할(Instance Segmentation): 같은 클래스의 서로 다른 객체 구분.
- 자세 추정(Pose Estimation): 사람의 주요 신체 부위 좌표 예측. -------------|
- 얼굴 랜드마크 탐지(Facial Landmark Detection): 얼굴의 주요 특징점 예측. --|-> 이 두 개는 각 좌표에 대한 정확한 레이블링이 필요해 비용이 상당하다..

**자기 지도 학습(Self-Supervised Learning)**
- 지도 학습의 가장 큰 단점인 대량의 레이블링된 데이터를 준비하기 위해 비용과 시간이 많이 든다는 것을 해결하기 위해 등장
- 레이블이 없는 데이터로 학습
- 사전 학습(Pre-Training)과 미세 조정(Fine-Tuning)의 두 단계로 진행됨

- 사전 학습 단계: 실제 풀고자 하는 진짜 문제(Downstream Task) 대신 가짜 문제(Pretext Task)를 새롭게 정의하여 해결(이 과정에서 레이블이 없는 데이터 활용)
- 미세 조정 단계: 레이블이 있는 데이터를 이용하여 일반적인 지도 학습 방식으로 모델 조정

컴퓨터 비전 분야 예시(Context Prediction, Contrastive Learning)
Context Prediction: 사전 학습 단계에서 이미지의 구조 및 객체 간 위치 관계 학습 -> 이미지의 전반적인 구조 파악
- 학습 과정: 이미지에서 무작위로 위치를 선정해 특정 크기의 파란색 패치를 둠 -> 파란색 패치 주변에 동일한 크기의 패치들을 배치 -> 모델이 파란색 패치와 주변 패치들의 상대적 위치 관계를 예측하도록 학습
- 장점: 레이블 없는 데이터에 적용 가능, 패란색 패치의 위치를 임의로 선정할 수 있기에 학습 데이터를 무한히 생성 가능

Contrastive Learning: 출처가 같다면 당기고, 출처가 다르면 밀어내는 학습 방식 -> 이미지 간 유사도 파악
- 학습 방식: 하나의 이미지에 서로 다른 두 가지 변형(Augmentation)을 가한 후 변형된 이미지 쌍의 출처가 같은지 다른지 인식하도록 학습
- 학습 규칙: 같은 이미지에서 변형된 쌍은 출력값을 서로 가깝게 만들고 다른 이미지에서 변형된 쌍은 출력값을 서로 멀어지게 만듦.

자연어 처리 분야 예시(GPT, BERT)
GPT: 다음 단어를 예측하는 방식으로 학습
BERT: 문장에 빈칸을 만들고 빈칸에 알맞은 토큰을 예측(Masked Token Prediction)하는 방식과 두 문장이 연속된 문장인지 예측(Next Sentence Prediction)하는 방식을 동시에 사용
