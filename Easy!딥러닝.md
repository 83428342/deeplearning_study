*Chapter1*

AI -> ML -> DL 순으로 영역 좁아짐. ML의 핵심은 데이터 기반으로 학습한다는 점임. (<-> 규칙 기반)

**AI 번역**

- 번역 문제의 하나의 데이터는 원문과 그에 대응하는 번역문으로 구성된 쌍.
- 학습에 사용되지 않은 새로운 문장을 입력해 번역된 문장의 정확성을 확인해 모델 성능 평가함(Perplexity: 예측 능력 수치화, BLEU Score: 번역 품질 수치화).
- 토크나이징: 텍스트가 숫자가 아니기 때문에 처리하는 전처리 과정. 텍스트를 적절한 단위로 나누는 작업을 의미함.
ex) 나는 학생입니다 -> 나는/학생/입니다 의 세 토큰으로 나눔.
- 정리하면 자연어 처리의 번역 작업은 '텍스트 -> 숫자 시퀀스 변환 후 입력 -> 숫자 시퀀스 출력 -> 텍스트로 변환'임.

**지도 학습(Supervised Learning)**

- 머신러닝의 학습 방식은 지도 학습, 비지도 학습, 자기 지도 학습, 강화 학습으로 나눌 수 있음.

지도 학습이란 정답을 알고 있는 상태에서 학습하는 방식.
- 각 입력 데이터에 대한 정답을 부여하는 데이터 라벨링이 필수적
- 회귀(Regression, 연속적 레이블)와 분류(Classification, 이산적 레이블)로 나뉘어짐, 기계 번역은 토큰 분류라는 관점에서 분류이다.

컴퓨터 비전 분야 예시
- 분류(Classification): 이미지가 무엇을 나타내는지 하나의 클래스로 나타내는 것. 세 개 이상의 클래스를 포함하는 다중 분류도 있음.
- 위치 추정(Localization): 분류와 함께 수행되며 이미지 내 객체의 클래스를 판단하고 동시에 위치를 출력하는 것(박스의 중심 좌표, 높이, 너비를 나타냄). 박스 정보 예측은 회귀임.
- 객체 탐지(Object Detection): 한 이미지 내 여러 객체의 분류 및 위치 추정을 동시 수행.
ex) YOLO는 이미지를 그리드로 나누어 각 그리드 셀에서 분류 및 각각의 바운딩 박스에 대한 신뢰도(그리드 셀 내 객체의 중심이 존재할 가능성과 예측된 박스가 실제 객체와 겹치는 정도를 곱한 값)와 박스 정보(중심 좌표, 높이, 너비)를 예측함.
- 분할(Segmentation): 이미지의 모든 픽셀을 대상으로 각 픽셀이 어떤 클래스에 해당하는지 판단(이제 네모가 아닌 객체의 모양으로 출력 가능)
- 인스턴스 분할(Instance Segmentation): 같은 클래스의 서로 다른 객체 구분.
- 자세 추정(Pose Estimation): 사람의 주요 신체 부위 좌표 예측. -------------|
- 얼굴 랜드마크 탐지(Facial Landmark Detection): 얼굴의 주요 특징점 예측. --|-> 이 두 개는 각 좌표에 대한 정확한 레이블링이 필요해 비용이 상당하다..

**자기 지도 학습(Self-Supervised Learning)**
- 지도 학습의 가장 큰 단점인 대량의 레이블링된 데이터를 준비하기 위해 비용과 시간이 많이 든다는 것을 해결하기 위해 등장.
- 레이블이 없는 데이터로 학습.
- 사전 학습(Pre-Training)과 미세 조정(Fine-Tuning)의 두 단계로 진행됨.

- 사전 학습 단계: 실제 풀고자 하는 진짜 문제(Downstream Task) 대신 가짜 문제(Pretext Task)를 새롭게 정의하여 해결(이 과정에서 레이블이 없는 데이터 활용).
- 미세 조정 단계: 레이블이 있는 데이터를 이용하여 일반적인 지도 학습 방식으로 모델 조정.

컴퓨터 비전 분야 예시(Context Prediction, Contrastive Learning)
Context Prediction: 사전 학습 단계에서 이미지의 구조 및 객체 간 위치 관계 학습 -> 이미지의 전반적인 구조 파악.
- 학습 과정: 이미지에서 무작위로 위치를 선정해 특정 크기의 파란색 패치를 둠 -> 파란색 패치 주변에 동일한 크기의 패치들을 배치 -> 모델이 파란색 패치와 주변 패치들의 상대적 위치 관계를 예측하도록 학습.
- 장점: 레이블 없는 데이터에 적용 가능, 패란색 패치의 위치를 임의로 선정할 수 있기에 학습 데이터를 무한히 생성 가능.

Contrastive Learning: 출처가 같다면 당기고, 출처가 다르면 밀어내는 학습 방식 -> 이미지 간 유사도 파악.
- 학습 방식: 하나의 이미지에 서로 다른 두 가지 변형(Augmentation)을 가한 후 변형된 이미지 쌍의 출처가 같은지 다른지 인식하도록 학습.
- 학습 규칙: 같은 이미지에서 변형된 쌍은 출력값을 서로 가깝게 만들고 다른 이미지에서 변형된 쌍은 출력값을 서로 멀어지게 만듦.

자연어 처리 분야 예시(GPT, BERT) <- 텍스트 그 자체가 입력이자 정답이 되므로 인위적 레이블링 필요없음.
GPT: 다음 단어를 예측하는 방식으로 학습
BERT: 문장에 빈칸을 만들고 빈칸에 알맞은 토큰을 예측(Masked Token Prediction)하는 방식과 두 문장이 연속된 문장인지 예측(Next Sentence Prediction)하는 방식을 동시에 사용.

**비지도 학습(Unsupervised Learning)**
- 정답이 주어지지 않은 상태에서 데이터의 특징을 스스로 학습하는 방식.

군집화(Clustering)
- 비슷한 특성을 가진 데이터들을 그룹으로 묶는 방법.
- K-means, DBSCAN 등이 있음.

차원 축소
- 데이터의 중요 특성을 유지하면서 데이터의 복잡성을 줄임.
- PCA, SVD 등이 있음.

**강화 학습(Reinforcement Learning)**
- 특정한 행동을 강화시키는 학습 방식.
- 행동(Action)에 대한 보상(Reward)을 줌으로써 그 행동을 강화하는 것이 핵심.
- 알파고도 강화학습의 예시임(이기는 수를 뒀을 때 해당 행동에 Reward를 줌).
- 규칙을 알려주지 않아도 적절한 보상을 주는 것만으로 학습시키는 것이 핵심.
- 용어1: Agent(행동을 취하는 주체), Action(Agent가 취할 수 있는 모든 행동), Reward(Agent가 Action에 따라 받게 되는 보상. 강화 학습의 핵심 전제는 Agent가 Reward를 최대화하려 한다는 것), Environment(강화 학습이 일어나는 공간)
- 용어2: State(환경의 현재 상태를 나타냄), 행동 가치 함수 Q(특정 State에서 특정 Action을 했을 때 현재와 미래에 얻을 수 있는 Reward 합의 기댓값), Episode(완료까지의 하나의 완전한 시행)
- 용어3: Q-Learning(Episode 내에서 Action을 여러 번 수행하여 Q 값을 반복적으로 업데이트해 최적의 행동 가치를 학습하는 방법. 현재 State와 Action, Reward, 다음 State의 정보를 사용하여 Q값 갱신), 심층 강화 학습(Deep Reinforcement Learning: Q-Learning에서 Q값을 딥러닝을 이용해 학습)
- 용어4: Exploration(기존에 학습하지 않은 새로운 방법을 찾는 것, &epsilon;-Greedy 기법의 &epsilon;값을 0과 1 사이로 조정해 일탈 빈도 조정), Exploitation(기존 지식을 활용하는 것, Exploration과 균형을 이루어야 함), Discount Factor &gamma;(Q값을 현재 시점으로 가져올 때 곱하는 0과 1 사이의 값. 1에 가까울수록 미래의 보상을 중요하게 여김)

*Chapter2*

인공 신경망(Artificial Neural Network)
- 곱하고 더하고 액티베이션하는 과정의 연속
- 활성화 함수(Activation Function): 들어오는 값에 따라 나가는 값 결정, Unit Step Function(계단 함수: 들어온 값 총합 양수면 1, 아니면 0), Linear Activation(선형 액티베이션: 들어온 값 그대로 출력) 등 존재.
- weight, bias를 넣어 민감도 조절.
- 노드끼리 모두 연결된 층은 FC(Fully-Connected) 레이어라고 함
- MLP(Multi-Layer Perceptron): 인풋, 아웃풋, 히든 레이어를 하나 이상 가지면서 모든 레이어가 FC 레이어인 신경망
- 딥러닝의 핵심은 weight와 bias를 어떻게 조정하는지이고 이것을 학습이라 함(weight만 조정하는 것이 아님!).

Loss
- Loss를 단순히 각각 데이터 세트의 loss를 더한 값으로 하면 양수와 음수 모두 포함되기 때문에 정확한 loss값 추정이 어려울 수 있음 -> 제곱해서 더하거나 절댓값을 더해야 함. 단, 제곱 시에는 Outlier(이상치)에 더 민감하게 반응 -> 절댓값 에러보다 이상치에 더 가깝게 예측선을 수정함.
- MSE(Mean Squared Error) Loss: 에러를 제곱한 후 더해 평균냄
- MAE(Mean Absolute Error) Loss: 에러에 절댓값을 씌운 후 더해 평균냄
- 
